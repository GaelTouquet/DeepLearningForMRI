{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "dce82a05f476f8a58d7048b59a51c4c76d4f564fd075bf13744563ee54d8455e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "from plotting import data_plot, hf_format\n",
    "from NN.Generators import DataGenerator_kspace_to_img\n",
    "from NN.architectures import reconGAN_Unet_kspace_to_img, my_ssim\n",
    "from utils.fastMRI_utils import ifft, fft\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import model_from_json\n",
    "tf.config.set_visible_devices([],'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ifft_layer(kspace):\n",
    "    real = Lambda(lambda kspace : kspace[:,:,:,0])(kspace)\n",
    "    imag = Lambda(lambda kspace : kspace[:,:,:,1])(kspace)\n",
    "    kspace_complex = tf.complex(real,imag)\n",
    "    kspace_complex = tf.signal.ifftshift(kspace_complex,axes=[1,2])\n",
    "    rec1 = tf.signal.ifft2d(kspace_complex)\n",
    "    rec1 = tf.signal.fftshift(rec1,axes=[1,2])\n",
    "    rec1 = tf.abs(rec1)#for loic images tf.abs(tf.signal.ifft2d(kspace_complex))\n",
    "    rec1 = tf.expand_dims(rec1, -1)\n",
    "    return rec1\n",
    "\n",
    "def nrmse(y_true, y_pred):\n",
    "    denom = tf.sqrt(tf.keras.backend.mean(tf.square(y_true), axis=(1,2,3)))\n",
    "    return tf.sqrt(tf.keras.backend.mean(tf.square(y_pred - y_true), axis=(1,2,3)))\\\n",
    "    /denom\n",
    "\n",
    "def reduced_nrmse(y_true, y_pred):\n",
    "    denom = tf.sqrt(tf.keras.backend.mean(tf.square(y_true), axis=(1,2,3)))\n",
    "    nrmse= tf.sqrt(tf.keras.backend.mean(tf.square(y_pred - y_true), axis=(1,2,3)))/denom\n",
    "    return tf.reduce_mean(nrmse)\n",
    "\n",
    "def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True, kernel_initializer=\"he_normal\"):\n",
    "    # first layer\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=kernel_initializer,\n",
    "               padding=\"same\")(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    # second layer\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=kernel_initializer,\n",
    "               padding=\"same\")(x)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    # third layer\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=kernel_initializer,\n",
    "               padding=\"same\")(x)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "def get_unet(input_img, n_filters=16, dropout=0.5, batchnorm=True, kernel_initializer=\"he_normal\"):\n",
    "    \n",
    "#    print(input_img)\n",
    "    # contracting path\n",
    "#    input_img=(input_img-1000)/1000\n",
    "    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm, kernel_initializer=kernel_initializer)\n",
    "    p1 = MaxPooling2D((2, 2)) (c1)\n",
    "    p1 = Dropout(dropout*0.5)(p1)\n",
    "\n",
    "    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm, kernel_initializer=kernel_initializer)\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "\n",
    "    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm, kernel_initializer=kernel_initializer)\n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "\n",
    "    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm, kernel_initializer=kernel_initializer)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "    \n",
    "    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm, kernel_initializer=kernel_initializer)\n",
    "    \n",
    "    # expansive path\n",
    "    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = Dropout(dropout)(u6)\n",
    "    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm, kernel_initializer=kernel_initializer)\n",
    "\n",
    "    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = Dropout(dropout)(u7)\n",
    "    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm, kernel_initializer=kernel_initializer)\n",
    "\n",
    "    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    u8 = Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm, kernel_initializer=kernel_initializer)\n",
    "\n",
    "    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    u9 = Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm, kernel_initializer=kernel_initializer)\n",
    "   \n",
    "    outkspace = Conv2D(2, (1, 1), activation='linear') (c9)\n",
    "    \n",
    "    outkspace_comb = Add()([outkspace,input_img])\n",
    "\n",
    "    \n",
    "    img_rec = Lambda(ifft_layer)(outkspace_comb)\n",
    "    \n",
    "    d1 = conv2d_block(img_rec, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm, kernel_initializer=kernel_initializer)\n",
    "    k1 = MaxPooling2D((2, 2)) (d1)\n",
    "    k1 = Dropout(dropout*0.5)(k1)\n",
    "\n",
    "    d2 = conv2d_block(k1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm, kernel_initializer=kernel_initializer)\n",
    "    k2 = MaxPooling2D((2, 2)) (d2)\n",
    "    k2 = Dropout(dropout)(k2)\n",
    "\n",
    "    d3 = conv2d_block(k2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm, kernel_initializer=kernel_initializer)\n",
    "    k3 = MaxPooling2D((2, 2)) (d3)\n",
    "    k3 = Dropout(dropout)(k3)\n",
    "\n",
    "    d4 = conv2d_block(k3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm, kernel_initializer=kernel_initializer)\n",
    "    k4 = MaxPooling2D(pool_size=(2, 2)) (d4)\n",
    "    k4 = Dropout(dropout)(k4)\n",
    "    \n",
    "    d5 = conv2d_block(k4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm, kernel_initializer=kernel_initializer)\n",
    "    \n",
    "    # expansive path\n",
    "    v6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (d5)\n",
    "    v6 = concatenate([v6, d4])\n",
    "    v6 = Dropout(dropout)(v6)\n",
    "    d6 = conv2d_block(v6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm, kernel_initializer=kernel_initializer)\n",
    "\n",
    "    v7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (d6)\n",
    "    v7 = concatenate([v7, d3])\n",
    "    v7 = Dropout(dropout)(v7)\n",
    "    d7 = conv2d_block(v7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm, kernel_initializer=kernel_initializer)\n",
    "\n",
    "    v8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (d7)\n",
    "    v8 = concatenate([v8, d2])\n",
    "    v8 = Dropout(dropout)(v8)\n",
    "    d8 = conv2d_block(v8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm, kernel_initializer=kernel_initializer)\n",
    "\n",
    "    v9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (d8)\n",
    "    v9 = concatenate([v9, d1], axis=3)\n",
    "    v9 = Dropout(dropout)(v9)\n",
    "    d9 = conv2d_block(v9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm, kernel_initializer=kernel_initializer)\n",
    "   \n",
    "    outimg = Conv2D(1, (1, 1), activation='linear') (d9)\n",
    "    # outimg = Add()([outimg,img_rec])\n",
    "\n",
    "    model = Model(inputs=[input_img], outputs=[outkspace_comb,outimg])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, Dropout, Conv2DTranspose, concatenate, Add, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "h5f = h5py.File(r'D:\\NN_DATA\\singlecoil_acc12_ksri_imgri__10midslices_densedpointmasked_nonorm\\train\\file1000001.h5','r')\n",
    "inp = h5f['kspace_masked'][0:8,:,:,:]\n",
    "model_path = r'C:\\Users\\touquet\\kspace_gen_MS07.h5'\n",
    "input_shape = Input((256, 256, 2))\n",
    "model = get_unet(input_shape, n_filters=16, dropout=0.05, batchnorm=True, kernel_initializer=\"zeros\")\n",
    "model.load_weights(model_path)\n",
    "outp = model.predict(inp)\n",
    "plt.imshow(outp[1][0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = r'D:\\NN_DATA\\singlecoil_acc12_ksri_imgri_normed_zerocentered_10midslices\\trainingsaves_ReconGAN_Unet_img_to_kspace__l2_Mar_16_13_14'\n",
    "json_file = os.path.join(model_path,'model_save.json')\n",
    "if os.path.isfile(json_file):\n",
    "    json_file = open(json_file, 'r')\n",
    "    model = model_from_json(json_file.read())\n",
    "    json_file.close()\n",
    "\n",
    "data_file_path = '\\\\'.join(model_path.split('\\\\')[:-1]+['val','file1000000.h5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(data_file_path,'r')\n",
    "comp = f['image_ground_truth'].value\n",
    "inp = f['kspace_ground_truth'].value\n",
    "pred = model.predict(inp)\n",
    "inp[:,:,:,0], inp[:,:,:,1] = hf_format(inp[:,:,:,0],inp[:,:,:,1],is_realim=True,output_ri=True)\n",
    "# outp[:,:,:,0], outp[:,:,:,1] = hf_format(outp[:,:,:,0],outp[:,:,:,1],False,True)\n",
    "compl_img = ifft(inp[0,:,:,0]+1j*inp[0,:,:,1])\n",
    "outp = np.zeros(inp.shape)\n",
    "outp[0,:,:,0] = np.real(compl_img)\n",
    "outp[0,:,:,1] = np.imag(compl_img)\n",
    "data_plot([comp[0],pred[0],outp[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_test = np.zeros((256,256),dtype=np.complex)\n",
    "# ks_test[:,:] += 10000\n",
    "ks_test[112:126,112:126] += 10000\n",
    "img_test = ifft(ks_test)\n",
    "displ = np.zeros((256,256,2))\n",
    "displ[:,:,0] = np.real(img_test)\n",
    "displ[:,:,1] = np.imag(img_test)\n",
    "displ2 = np.zeros((256,256,2))\n",
    "displ2[:,:,0] = np.real(ks_test)\n",
    "displ2[:,:,1] = np.imag(ks_test)\n",
    "data_plot([displ,displ2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from NN.Masks import CenteredRandomMask\n",
    "input_mask = CenteredRandomMask(acceleration=8, center_fraction=(4./100.), seed=0xdeadbeef)\n",
    "to_mask = np.ones((256,256))\n",
    "plt.imshow(input_mask(to_mask),cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File(r'D:\\LB-NN-MONICA-KSPACE\\Train-k-space-monica-15.hdf5','r')\n",
    "kspace1 = hf[hf['index'][1]]['VolumeKspace'][5][:,:,0]+1j*hf[hf['index'][1]]['VolumeKspace'][5][:,:,1]\n",
    "test1= kspace1==0.\n",
    "print(test1)\n",
    "n_zeroes = np.sum(test1)\n",
    "n_pixels = kspace1.shape[0]*kspace1.shape[1]\n",
    "print(1 - n_zeroes/n_pixels)\n",
    "img1 = np.fft.fftshift(ifft(kspace1))\n",
    "# no phase at all, much better looking images after mask (could be monica's masks or brains look better, also size of object (lots of emptiness in brain images)), no clean kspaces?!\n",
    "plt.imshow(np.real(img1))\n",
    "# plt.imshow(np.real(img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf2 = h5py.File(r'D:\\LB-NN-MONICA-KSPACE\\Train-k-space.hdf5','r')\n",
    "kspace2 = hf2[hf2['index'][1]]['VolumeKspace'][5][:,:,0]+1j*hf2[hf2['index'][1]]['VolumeKspace'][5][:,:,1]\n",
    "img2 = ifft(kspace2)\n",
    "plt.imshow(hf2[hf2['index'][1]]['VolumeKspace'][5][:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itkimage = sitk.ReadImage(r'D:\\LB-NN-MONICA-KSPACE\\Masks-Monica\\undersampl_0p15\\ima_1.mhd')\n",
    "itkarray = sitk.GetArrayFromImage(itkimage)\n",
    "print(np.sum(itkarray)/(256*256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NN.Masks import PolynomialMaskGenerator\n",
    "input_mask = PolynomialMaskGenerator((256,256),sampling_factor=0.15,dim=2)\n",
    "data_path = r'D:\\NN_DATA\\singlecoil_acc12_ksri_imgri_normed_zerocentered_10midslices_densedpointmasked\\train\\file1000021.h5'\n",
    "kspace = h5py.File(data_path,'r')['kspace_ground_truth'].value\n",
    "kspace = kspace[0,:,:,0] + 1j*kspace[0,:,:,1]\n",
    "mask_loic = itkarray*kspace\n",
    "mask_gael = input_mask(kspace)\n",
    "mask_loic = ifft(mask_loic)\n",
    "mask_gael = ifft(mask_gael)\n",
    "displ_loic = np.zeros((256,256,2),dtype=np.double)\n",
    "displ_gael = np.zeros((256,256,2),dtype=np.double)\n",
    "displ_loic[:,:,0] = np.real(mask_loic)\n",
    "displ_loic[:,:,1] = np.imag(mask_loic)\n",
    "displ_gael[:,:,0] = np.real(mask_gael)\n",
    "displ_gael[:,:,1] = np.imag(mask_gael)\n",
    "data_plot([displ_gael,displ_loic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ifft_layer(kspace):\n",
    "    real = Lambda(lambda kspace : kspace[:,:,:,0])(kspace)\n",
    "    imag = Lambda(lambda kspace : kspace[:,:,:,1])(kspace)\n",
    "    kspace_complex = tf.complex(real,imag)\n",
    "    # rec1 = tf.abs(tf.signal.ifft2d(kspace_complex))\n",
    "    kspace_complex = tf.signal.ifftshift(kspace_complex,axes=[1,2])\n",
    "    rec1 = tf.signal.ifft2d(kspace_complex)\n",
    "    rec1 = tf.signal.fftshift(rec1,axes=[1,2])\n",
    "    rec1 = tf.abs(rec1)#for loic images tf.abs(tf.signal.ifft2d(kspace_complex))\n",
    "    rec1 = tf.expand_dims(rec1, -1)\n",
    "    return rec1\n",
    "\n",
    "def nrmse(y_true, y_pred):\n",
    "    denom = tf.sqrt(tf.keras.backend.mean(tf.square(y_true), axis=(1,2,3)))\n",
    "    return tf.sqrt(tf.keras.backend.mean(tf.square(y_pred - y_true), axis=(1,2,3)))\\\n",
    "    /denom\n",
    "\n",
    "def reduced_nrmse(y_true, y_pred):\n",
    "    denom = tf.sqrt(tf.keras.backend.mean(tf.square(y_true), axis=(1,2,3)))\n",
    "    nrmse= tf.sqrt(tf.keras.backend.mean(tf.square(y_pred - y_true), axis=(1,2,3)))/denom\n",
    "    return tf.reduce_mean(nrmse)\n",
    "\n",
    "def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):\n",
    "    # first layer\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
    "               padding=\"same\")(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    # second layer\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
    "               padding=\"same\")(x)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    # third layer\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
    "               padding=\"same\")(x)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "def get_unet(input_img, n_filters=16, dropout=0.5, batchnorm=True):\n",
    "    \n",
    "#    print(input_img)\n",
    "    # contracting path\n",
    "#    input_img=(input_img-1000)/1000\n",
    "    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
    "    p1 = MaxPooling2D((2, 2)) (c1)\n",
    "    p1 = Dropout(dropout*0.5)(p1)\n",
    "\n",
    "    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "\n",
    "    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "\n",
    "    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "    \n",
    "    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)\n",
    "    \n",
    "    # expansive path\n",
    "    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = Dropout(dropout)(u6)\n",
    "    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = Dropout(dropout)(u7)\n",
    "    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    u8 = Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    u9 = Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
    "   \n",
    "    outkspace = Conv2D(2, (1, 1), activation='linear') (c9)\n",
    "    \n",
    "    outkspace_comb = Add()([outkspace,input_img])\n",
    "\n",
    "    \n",
    "    img_rec = Lambda(ifft_layer)(outkspace_comb)\n",
    "    \n",
    "    d1 = conv2d_block(img_rec, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
    "    k1 = MaxPooling2D((2, 2)) (d1)\n",
    "    k1 = Dropout(dropout*0.5)(k1)\n",
    "\n",
    "    d2 = conv2d_block(k1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
    "    k2 = MaxPooling2D((2, 2)) (d2)\n",
    "    k2 = Dropout(dropout)(k2)\n",
    "\n",
    "    d3 = conv2d_block(k2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
    "    k3 = MaxPooling2D((2, 2)) (d3)\n",
    "    k3 = Dropout(dropout)(k3)\n",
    "\n",
    "    d4 = conv2d_block(k3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
    "    k4 = MaxPooling2D(pool_size=(2, 2)) (d4)\n",
    "    k4 = Dropout(dropout)(k4)\n",
    "    \n",
    "    d5 = conv2d_block(k4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)\n",
    "    \n",
    "    # expansive path\n",
    "    v6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (d5)\n",
    "    v6 = concatenate([v6, d4])\n",
    "    v6 = Dropout(dropout)(v6)\n",
    "    d6 = conv2d_block(v6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    v7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (d6)\n",
    "    v7 = concatenate([v7, d3])\n",
    "    v7 = Dropout(dropout)(v7)\n",
    "    d7 = conv2d_block(v7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    v8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (d7)\n",
    "    v8 = concatenate([v8, d2])\n",
    "    v8 = Dropout(dropout)(v8)\n",
    "    d8 = conv2d_block(v8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    v9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (d8)\n",
    "    v9 = concatenate([v9, d1], axis=3)\n",
    "    v9 = Dropout(dropout)(v9)\n",
    "    d9 = conv2d_block(v9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
    "   \n",
    "    outimg = Conv2D(1, (1, 1), activation='linear') (d9)\n",
    "\n",
    "    model = Model(inputs=[input_img], outputs=[outkspace_comb,outimg])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generatorKspaceUnet3 import DataGenerator\n",
    "from NN.architectures import reconGAN_Wnet_intermediate\n",
    "train_gen = DataGenerator([r'D:\\LB-NN-MONICA-KSPACE\\Train-k-space-monica-15.hdf5'],batch_size=16, dim=(256,256),training=False)\n",
    "model = reconGAN_Wnet_intermediate((256,256,2), 16, 16, skip=True,realimag_img=True, realimag_kspace=True,normalise_image=True,center_normalised_values=True,kernel_initializer='zeros')\n",
    "model.load_weights(r'D:\\NN_DATA\\singlecoil_acc12_ksri_imgri_normed_zerocentered_10midslices_densedpointmasked\\trainingsaves_ReconGAN_Unet_kspace_to_img_intermoutput_ssimLoic_data_test_Mar_17_17_58\\best.h5')\n",
    "outp = model.predict(train_gen[0][0])\n",
    "# print(outp[0].shape)\n",
    "display = np.zeros((256,256,2),dtype=np.float)\n",
    "display = outp[0][0]\n",
    "kspace_compl_to_display = train_gen[0][0][0,:,:,0] + 1j*train_gen[0][0][0,:,:,1]\n",
    "input_compl = np.fft.fftshift(ifft(kspace_compl_to_display))\n",
    "input_todisplay = np.zeros((256,256,2), dtype=np.float)\n",
    "input_todisplay[:,:,0] = np.real(input_compl)\n",
    "input_todisplay[:,:,1] = np.imag(input_compl)\n",
    "gt = np.zeros((256,256,2,1),dtype=np.float)\n",
    "inpu = np.zeros((256,256,2,1),dtype=np.float)\n",
    "inter_display = np.zeros((256,256,2),dtype=np.float)\n",
    "inter_display[:,:,:] = outp[1][0]\n",
    "gt[:,:,0,:] = train_gen[0][1][1][0]\n",
    "data_plot([input_todisplay,inter_display,display,gt[:,:,:,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, Dropout, Conv2DTranspose, concatenate, Add, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "input_loic = Input((256,256,2))\n",
    "model_loic = get_unet(input_loic, n_filters=16, dropout=0.05, batchnorm=True)\n",
    "model_loic.load_weights(r'C:\\Users\\touquet\\Documents\\Code\\DeepLearningForMRI\\LB-NN-MONICA-KSPACE\\kspace_gen_MS16.h5')\n",
    "outp_loic = model_loic.predict(train_gen[0][0])\n",
    "display_loic_compl_kspace = np.zeros((256,256,2),dtype=np.float)\n",
    "display_loic_compl_kspace = outp_loic[0][0,:,:,0] + 1j*outp_loic[0][0,:,:,1]\n",
    "inter_loic_compl_img = ifft(display_loic_compl_kspace)\n",
    "inter_display_loic = np.zeros((256,256,2),dtype=np.float)\n",
    "inter_display_loic[:,:,0] = np.abs(inter_loic_compl_img)\n",
    "display_loic = np.zeros((256,256,2),dtype=np.float)\n",
    "display_loic[:,:,0] = outp_loic[1][0,:,:,0]\n",
    "data_plot([input_todisplay,inter_display_loic,display_loic,gt[:,:,:,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generatorKspaceUnet3 import DataGenerator\n",
    "from NN.architectures import reconGAN_Wnet_intermediate\n",
    "train_gen = DataGenerator([r'D:\\LB-NN-MONICA-KSPACE\\Train-k-space-monica-15.hdf5'],batch_size=16, dim=(256,256),training=False)\n",
    "model = reconGAN_Wnet_intermediate((256,256,2), 16, 16, skip=True,realimag_img=True, realimag_kspace=True,normalise_image=True,center_normalised_values=True,kernel_initializer='zeros')\n",
    "json_file= r'D:\\NN_DATA\\singlecoil_acc12_ksri_imgri_normed_zerocentered_10midslices_densedpointmasked\\trainingsaves_ReconGAN_Unet_kspace_to_img_intermoutput_ssimLoic_data_arch_loss_Mar_18_14_42\\model_save.json'\n",
    "json_file = open(json_file, 'r')\n",
    "model = model_from_json(json_file.read())\n",
    "json_file.close()\n",
    "model.load_weights(r'D:\\NN_DATA\\singlecoil_acc12_ksri_imgri_normed_zerocentered_10midslices_densedpointmasked\\trainingsaves_ReconGAN_Unet_kspace_to_img_intermoutput_ssimLoic_data_arch_loss_Mar_18_14_42\\epoch05.h5')\n",
    "outp = model.predict(train_gen[0][0])\n",
    "# print(outp[0].shape)\n",
    "display = np.zeros((256,256,2),dtype=np.float)\n",
    "display = outp[0][0]\n",
    "kspace_compl_to_display = train_gen[0][0][0,:,:,0] + 1j*train_gen[0][0][0,:,:,1]\n",
    "input_compl = np.fft.fftshift(ifft(kspace_compl_to_display))\n",
    "input_todisplay = np.zeros((256,256,2), dtype=np.float)\n",
    "input_todisplay[:,:,0] = np.real(input_compl)\n",
    "input_todisplay[:,:,1] = np.imag(input_compl)\n",
    "gt = np.zeros((256,256,2,1),dtype=np.float)\n",
    "inpu = np.zeros((256,256,2,1),dtype=np.float)\n",
    "inter_display = np.zeros((256,256,2),dtype=np.float)\n",
    "inter_display[:,:,:] = outp[1][0]\n",
    "gt[:,:,0,:] = train_gen[0][1][1][0]\n",
    "data_plot([input_todisplay,inter_display,display,gt[:,:,:,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generatorKspaceUnet3 import DataGenerator\n",
    "from NN.architectures import reconGAN_Wnet_intermediate\n",
    "train_gen = DataGenerator([r'D:\\LB-NN-MONICA-KSPACE\\Train-k-space-monica-15.hdf5'],batch_size=16, dim=(256,256),training=False)\n",
    "model = reconGAN_Wnet_intermediate((256,256,2), 16, 16, skip=True,realimag_img=True, realimag_kspace=True,normalise_image=True,center_normalised_values=True,kernel_initializer='zeros')\n",
    "json_file= r'D:\\NN_DATA\\singlecoil_acc12_ksri_imgri_normed_zerocentered_10midslices_densedpointmasked\\trainingsaves_ReconGAN_Unet_kspace_to_img_intermoutput_ssimLoic_data_justarch_Mar_18_16_09\\model_save.json'\n",
    "json_file = open(json_file, 'r')\n",
    "model = model_from_json(json_file.read())\n",
    "json_file.close()\n",
    "model.load_weights(r'D:\\NN_DATA\\singlecoil_acc12_ksri_imgri_normed_zerocentered_10midslices_densedpointmasked\\trainingsaves_ReconGAN_Unet_kspace_to_img_intermoutput_ssimLoic_data_justarch_Mar_18_16_09\\best.h5')\n",
    "outp = model.predict(train_gen[0][0])\n",
    "# print(outp[0].shape)\n",
    "display = np.zeros((256,256,2),dtype=np.float)\n",
    "display = outp[0][0]\n",
    "kspace_compl_to_display = train_gen[0][0][0,:,:,0] + 1j*train_gen[0][0][0,:,:,1]\n",
    "input_compl = np.fft.fftshift(ifft(kspace_compl_to_display))\n",
    "input_todisplay = np.zeros((256,256,2), dtype=np.float)\n",
    "input_todisplay[:,:,0] = np.real(input_compl)\n",
    "input_todisplay[:,:,1] = np.imag(input_compl)\n",
    "gt = np.zeros((256,256,2,1),dtype=np.float)\n",
    "inpu = np.zeros((256,256,2,1),dtype=np.float)\n",
    "inter_display = np.zeros((256,256,2),dtype=np.float)\n",
    "inter_display[:,:,:] = outp[1][0]\n",
    "gt[:,:,0,:] = train_gen[0][1][1][0]\n",
    "data_plot([input_todisplay,inter_display,display,gt[:,:,:,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generatorKspaceUnet3 import DataGenerator\n",
    "from NN.Generators import DataGenerator_kspace_img_interm_kspace_onlyabsimg\n",
    "from NN.architectures import reconGAN_Wnet_intermediate\n",
    "train_gen = DataGenerator_kspace_img_interm_kspace_onlyabsimg(r'D:\\NN_DATA\\singlecoil_acc12_ksri_imgri_normed_zerocentered_10midslices_densedpointmasked\\train',batch_size=16)\n",
    "# train_gen = DataGenerator([r'D:\\LB-NN-MONICA-KSPACE\\Train-k-space-monica-15.hdf5'],batch_size=16, dim=(256,256),training=False)\n",
    "model = reconGAN_Wnet_intermediate((256,256,2), 16, 16, skip=True,realimag_img=True, realimag_kspace=True,normalise_image=True,center_normalised_values=True,kernel_initializer='zeros')\n",
    "json_file= r'D:\\NN_DATA\\singlecoil_acc12_ksri_imgri_normed_zerocentered_10midslices_densedpointmasked\\trainingsaves_ReconGAN_Unet_kspace_to_img_intermoutput_ssim_Mar_19_08_17\\model_save.json'\n",
    "json_file = open(json_file, 'r')\n",
    "model = model_from_json(json_file.read())\n",
    "json_file.close()\n",
    "model.load_weights(r'D:\\NN_DATA\\singlecoil_acc12_ksri_imgri_normed_zerocentered_10midslices_densedpointmasked\\trainingsaves_ReconGAN_Unet_kspace_to_img_intermoutput_ssim_Mar_19_08_17\\best.h5')\n",
    "outp = model.predict(train_gen[0][0])\n",
    "# print(outp[0].shape)\n",
    "display = np.zeros((256,256,2,1),dtype=np.float)\n",
    "display[:,:,0,:] = outp[1][0]\n",
    "kspace_compl_to_display = train_gen[0][0][0,:,:,0] + 1j*train_gen[0][0][0,:,:,1]\n",
    "input_compl = ifft(kspace_compl_to_display)\n",
    "input_todisplay = np.zeros((256,256,2), dtype=np.float)\n",
    "input_todisplay[:,:,0] = np.real(input_compl)\n",
    "input_todisplay[:,:,1] = np.imag(input_compl)\n",
    "gt = np.zeros((256,256,2,1),dtype=np.float)\n",
    "inter_display = np.zeros((256,256,2),dtype=np.float)\n",
    "interk_compl = outp[0][0][:,:,0] +1j*outp[0][0][:,:,1]\n",
    "interimg_compl = ifft(interk_compl)\n",
    "inter_display[:,:,0] = np.abs(interimg_compl) \n",
    "gt[:,:,0,:] = train_gen[0][1][1][0]\n",
    "data_plot([input_todisplay,inter_display,display,gt[:,:,:,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generatorKspaceUnet3 import DataGenerator\n",
    "from NN.Generators import DataGenerator_kspace_img_interm_kspace_onlyabsimg, DataGenerator_kspace_img_interm_kspace\n",
    "from NN.architectures import reconGAN_Wnet_intermediate\n",
    "train_gen = DataGenerator_kspace_img_interm_kspace(r'D:\\NN_DATA\\singlecoil_acc12_ksri_imgri_normed_zerocentered_10midslices_densedpointmasked\\train',batch_size=16)\n",
    "# train_gen = DataGenerator([r'D:\\LB-NN-MONICA-KSPACE\\Train-k-space-monica-15.hdf5'],batch_size=16, dim=(256,256),training=False)\n",
    "model = reconGAN_Wnet_intermediate((256,256,2), 16, 16, skip=True,realimag_img=True, realimag_kspace=True,normalise_image=True,center_normalised_values=True,kernel_initializer='zeros')\n",
    "json_file= r'D:\\NN_DATA\\singlecoil_acc12_ksri_imgri_normed_zerocentered_10midslices_densedpointmasked\\trainingsaves_ReconGAN_Unet_kspace_to_img_intermoutput_ssim_Mar_19_10_56\\model_save.json'\n",
    "json_file = open(json_file, 'r')\n",
    "model = model_from_json(json_file.read())\n",
    "json_file.close()\n",
    "model.load_weights(r'D:\\NN_DATA\\singlecoil_acc12_ksri_imgri_normed_zerocentered_10midslices_densedpointmasked\\trainingsaves_ReconGAN_Unet_kspace_to_img_intermoutput_ssim_Mar_19_10_56\\best.h5')\n",
    "outp = model.predict(train_gen[0][0])\n",
    "# print(outp[0].shape)\n",
    "display = np.zeros((256,256,2),dtype=np.float)\n",
    "display[:,:,:] = outp[1][0]\n",
    "kspace_compl_to_display = train_gen[0][0][0,:,:,0] + 1j*train_gen[0][0][0,:,:,1]\n",
    "input_compl = ifft(kspace_compl_to_display)\n",
    "input_todisplay = np.zeros((256,256,2), dtype=np.float)\n",
    "input_todisplay[:,:,0] = np.real(input_compl)\n",
    "input_todisplay[:,:,1] = np.imag(input_compl)\n",
    "gt = np.zeros((256,256,2),dtype=np.float)\n",
    "inter_display = np.zeros((256,256,2),dtype=np.float)\n",
    "interk_compl = outp[0][0][:,:,0] +1j*outp[0][0][:,:,1]\n",
    "interimg_compl = ifft(interk_compl)\n",
    "inter_display[:,:,0] = np.real(interimg_compl) \n",
    "inter_display[:,:,1] = np.imag(interimg_compl) \n",
    "gt[:,:,:] = train_gen[0][1][1][0]\n",
    "data_plot([input_todisplay,inter_display,display,gt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, Dropout, Conv2DTranspose, concatenate, Add, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from NN.Generators import DataGenerator_fullimg_abs_interm\n",
    "batch_size = 12\n",
    "train_gen = DataGenerator_fullimg_abs_interm(r'D:\\NN_DATA\\singlecoil_acc12_ksri_imgri_normed_zerocentered_10midslices_densedpointmasked\\train',batch_size=batch_size)\n",
    "validation_generator = DataGenerator_fullimg_abs_interm(r'D:\\NN_DATA\\singlecoil_acc12_ksri_imgri_normed_zerocentered_10midslices_densedpointmasked\\val',batch_size=batch_size)\n",
    "\n",
    "input_loic = Input((256,256,2))\n",
    "model_loic = get_unet(input_loic, n_filters=16, dropout=0.05, batchnorm=True)\n",
    "model_loic.load_weights(r'C:\\Users\\touquet\\Documents\\Code\\DeepLearningForMRI\\kspace_gen_MS14.h5')\n",
    "outp_loic = model_loic.predict(train_gen[0][0])\n",
    "display_loic_compl_kspace = np.zeros((256,256,2),dtype=np.float)\n",
    "display_loic_compl_kspace = outp_loic[0][0,:,:,0] + 1j*outp_loic[0][0,:,:,1]\n",
    "inter_loic_compl_img = ifft(display_loic_compl_kspace)\n",
    "inter_display_loic = np.zeros((256,256,2),dtype=np.float)\n",
    "inter_display_loic[:,:,0] = np.abs(inter_loic_compl_img)\n",
    "display_loic = np.zeros((256,256,2),dtype=np.float)\n",
    "display_loic[:,:,0] = outp_loic[1][0,:,:,0]\n",
    "# display_loic[:,:,1] = outp_loic[1][0,:,:,1]\n",
    "absgt = np.zeros((256,256,2),dtype=np.float)\n",
    "gt[:,:,:] = train_gen[0][1][1][0]\n",
    "absgt[:,:,0] = np.abs(gt[:,:,0] + 1j*gt[:,:,1])\n",
    "data_plot([input_todisplay,inter_display_loic,display_loic,absgt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}